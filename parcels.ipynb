{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early stage code for package classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for package classification\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd #for importing and managing datasets\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from keras.models import Sequential  #to initialze our neural network\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten  #Use to convert Pooled image into input later for fully connected layer\n",
    "from keras.layers import Dense  #Use this to add fully connect layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the CNN\n",
    "\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Convolution step\n",
    "\n",
    "### Step 2: Max Pooling step\n",
    "\n",
    "### Step 3: Convoltions step\n",
    "\n",
    "### Step 4: Max Pooling step\n",
    "\n",
    "### Step 5: Flattening step\n",
    "\n",
    "### Step 6: Full Connection step\n",
    "\n",
    "### Step 7: ReLU \n",
    "\n",
    "### Step 8: Sigmoid output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution.  We get as many feature maps as the number of filters we use\n",
    "\n",
    "classifier.add(Convolution2D(32,(3,3), input_shape=(64,64,3),activation='relu')) #HxWxChannels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pooling\n",
    "classifier.add(MaxPooling2D(pool_size= (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to improve test set accuracy by adding an additional convolutional layer and pooling layer\n",
    "classifier.add(Convolution2D(32,(3,3),activation='relu')) #HxWxChannels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pooling\n",
    "classifier.add(MaxPooling2D(pool_size= (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flattening: Taking all of our pooled feature maps and flattening them all into one single vector\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usojourn/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/usojourn/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Full Connection\n",
    "\n",
    "classifier.add(Dense(output_dim = 128, activation = 'relu')) #Common practice to pick a power of \n",
    "classifier.add(Dense(output_dim = 1, activation = 'sigmoid')) #Binary outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile our CNN\n",
    "classifier.compile(optimizer = 'adam',loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 178 images belonging to 2 classes.\n",
      "Found 42 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "179/179 [==============================] - 2s 9ms/step - loss: 0.7333 - acc: 0.5307 - val_loss: 0.6965 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 0.6977 - acc: 0.5251 - val_loss: 0.6937 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "179/179 [==============================] - 1s 8ms/step - loss: 0.6917 - acc: 0.5531 - val_loss: 0.6893 - val_acc: 0.5714\n",
      "Epoch 4/50\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 0.6928 - acc: 0.6034 - val_loss: 0.6687 - val_acc: 0.6429\n",
      "Epoch 5/50\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 0.6735 - acc: 0.6145 - val_loss: 0.6661 - val_acc: 0.5714\n",
      "Epoch 6/50\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 0.6262 - acc: 0.7151 - val_loss: 0.7224 - val_acc: 0.5714\n",
      "Epoch 7/50\n",
      "179/179 [==============================] - 2s 9ms/step - loss: 0.5753 - acc: 0.6927 - val_loss: 0.6751 - val_acc: 0.5714\n",
      "Epoch 8/50\n",
      "179/179 [==============================] - 1s 8ms/step - loss: 0.5667 - acc: 0.7318 - val_loss: 1.5032 - val_acc: 0.5476\n",
      "Epoch 9/50\n",
      "179/179 [==============================] - 1s 8ms/step - loss: 0.5189 - acc: 0.7486 - val_loss: 0.7597 - val_acc: 0.5952\n",
      "Epoch 10/50\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 0.5210 - acc: 0.7654 - val_loss: 0.9616 - val_acc: 0.4524\n",
      "Epoch 11/50\n",
      "179/179 [==============================] - 1s 8ms/step - loss: 0.5161 - acc: 0.7821 - val_loss: 0.8982 - val_acc: 0.5714\n",
      "Epoch 12/50\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 0.4226 - acc: 0.7989 - val_loss: 0.9505 - val_acc: 0.5238\n",
      "Epoch 13/50\n",
      "179/179 [==============================] - 1s 8ms/step - loss: 0.4369 - acc: 0.8045 - val_loss: 0.9369 - val_acc: 0.5714\n",
      "Epoch 14/50\n",
      "179/179 [==============================] - 1s 8ms/step - loss: 0.3974 - acc: 0.8045 - val_loss: 1.3022 - val_acc: 0.5000\n",
      "Epoch 15/50\n",
      "179/179 [==============================] - 1s 8ms/step - loss: 0.3678 - acc: 0.8492 - val_loss: 1.0390 - val_acc: 0.5952\n",
      "Epoch 16/50\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 0.3518 - acc: 0.8436 - val_loss: 1.1715 - val_acc: 0.5714\n",
      "Epoch 17/50\n",
      "179/179 [==============================] - 1s 8ms/step - loss: 0.3700 - acc: 0.8436 - val_loss: 1.1038 - val_acc: 0.5000\n",
      "Epoch 18/50\n",
      "179/179 [==============================] - 2s 9ms/step - loss: 0.4029 - acc: 0.8156 - val_loss: 1.1670 - val_acc: 0.5476\n",
      "Epoch 19/50\n",
      "179/179 [==============================] - 1s 8ms/step - loss: 0.3804 - acc: 0.8268 - val_loss: 1.1657 - val_acc: 0.4286\n",
      "Epoch 20/50\n",
      "179/179 [==============================] - 1s 8ms/step - loss: 0.3525 - acc: 0.8436 - val_loss: 1.1349 - val_acc: 0.5476\n",
      "Epoch 21/50\n",
      "179/179 [==============================] - 1s 8ms/step - loss: 0.2493 - acc: 0.9162 - val_loss: 1.2173 - val_acc: 0.5714\n",
      "Epoch 22/50\n",
      "179/179 [==============================] - 2s 9ms/step - loss: 0.2929 - acc: 0.8883 - val_loss: 1.4046 - val_acc: 0.5952\n",
      "Epoch 23/50\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 0.3015 - acc: 0.8715 - val_loss: 1.2016 - val_acc: 0.4762\n",
      "Epoch 24/50\n",
      "179/179 [==============================] - 1s 8ms/step - loss: 0.1860 - acc: 0.9330 - val_loss: 1.6468 - val_acc: 0.5000\n",
      "Epoch 25/50\n",
      "179/179 [==============================] - 1s 8ms/step - loss: 0.2831 - acc: 0.9106 - val_loss: 1.5443 - val_acc: 0.5238\n",
      "Epoch 26/50\n",
      "179/179 [==============================] - 1s 8ms/step - loss: 0.1925 - acc: 0.9385 - val_loss: 1.4480 - val_acc: 0.5714\n",
      "Epoch 27/50\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 0.1785 - acc: 0.9218 - val_loss: 1.3196 - val_acc: 0.5000\n",
      "Epoch 28/50\n",
      "179/179 [==============================] - 1s 8ms/step - loss: 0.2272 - acc: 0.8939 - val_loss: 1.3452 - val_acc: 0.5952\n",
      "Epoch 29/50\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 0.2011 - acc: 0.9330 - val_loss: 1.7358 - val_acc: 0.5000\n",
      "Epoch 30/50\n",
      "179/179 [==============================] - 2s 8ms/step - loss: 0.1397 - acc: 0.9441 - val_loss: 1.4131 - val_acc: 0.5952\n",
      "Epoch 31/50\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 0.1963 - acc: 0.9162 - val_loss: 1.3531 - val_acc: 0.5238\n",
      "Epoch 32/50\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 0.1604 - acc: 0.9274 - val_loss: 1.1727 - val_acc: 0.6190\n",
      "Epoch 33/50\n",
      "179/179 [==============================] - 1s 8ms/step - loss: 0.1556 - acc: 0.9553 - val_loss: 1.1858 - val_acc: 0.6667\n",
      "Epoch 34/50\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 0.1213 - acc: 0.9553 - val_loss: 1.3429 - val_acc: 0.6429\n",
      "Epoch 35/50\n",
      "179/179 [==============================] - 1s 8ms/step - loss: 0.2128 - acc: 0.9441 - val_loss: 1.3135 - val_acc: 0.6667\n",
      "Epoch 36/50\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 0.1034 - acc: 0.9609 - val_loss: 1.6271 - val_acc: 0.6429\n",
      "Epoch 37/50\n",
      "179/179 [==============================] - 1s 8ms/step - loss: 0.1505 - acc: 0.9609 - val_loss: 1.4021 - val_acc: 0.5952\n",
      "Epoch 38/50\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.0540 - acc: 0.9832 - val_loss: 1.4917 - val_acc: 0.5476\n",
      "Epoch 39/50\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 0.2133 - acc: 0.9218 - val_loss: 1.2701 - val_acc: 0.6429\n",
      "Epoch 40/50\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 0.0766 - acc: 0.9888 - val_loss: 1.4891 - val_acc: 0.5714\n",
      "Epoch 41/50\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 0.1997 - acc: 0.9330 - val_loss: 1.3767 - val_acc: 0.6190\n",
      "Epoch 42/50\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 0.0983 - acc: 0.9553 - val_loss: 1.6653 - val_acc: 0.6190\n",
      "Epoch 43/50\n",
      "179/179 [==============================] - 1s 8ms/step - loss: 0.0531 - acc: 0.9777 - val_loss: 1.8700 - val_acc: 0.5000\n",
      "Epoch 44/50\n",
      "179/179 [==============================] - 1s 7ms/step - loss: 0.0309 - acc: 0.9944 - val_loss: 1.9778 - val_acc: 0.5714\n",
      "Epoch 45/50\n",
      "179/179 [==============================] - 1s 8ms/step - loss: 0.0709 - acc: 0.9777 - val_loss: 1.8316 - val_acc: 0.5714\n",
      "Epoch 46/50\n",
      "179/179 [==============================] - 1s 6ms/step - loss: 0.0686 - acc: 0.9777 - val_loss: 2.1010 - val_acc: 0.6429\n",
      "Epoch 47/50\n",
      "179/179 [==============================] - 1s 8ms/step - loss: 0.1300 - acc: 0.9665 - val_loss: 1.7818 - val_acc: 0.6190\n",
      "Epoch 48/50\n",
      "179/179 [==============================] - 2s 8ms/step - loss: 0.0684 - acc: 0.9665 - val_loss: 1.9400 - val_acc: 0.5476\n",
      "Epoch 49/50\n",
      "179/179 [==============================] - 2s 10ms/step - loss: 0.0420 - acc: 0.9832 - val_loss: 2.6512 - val_acc: 0.5476\n",
      "Epoch 50/50\n",
      "179/179 [==============================] - 1s 8ms/step - loss: 0.0990 - acc: 0.9665 - val_loss: 1.8960 - val_acc: 0.5714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4f61df4eb8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we prepare to run the images througn the neural network\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#Image augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "#Test image augmentation\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#Making sure we have the right dimension size\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        'dataset2/training_set',\n",
    "        target_size=(64,64),\n",
    "        batch_size=1,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        'dataset2/test_set',\n",
    "        target_size=(64,64),\n",
    "        batch_size=1,\n",
    "        class_mode='binary')\n",
    "\n",
    "classifier.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=179,\n",
    "        epochs=50,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
